---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'The detection and influence of problematic item content in ability tests:
  An examination of sensitivity review practices for personnel selection test development'
subtitle: ''
summary: ''
authors:
- JamesGrand
- Juliya Golubovich
- Ann Marie Ryan
- Neal Schmitt
tags: [Sensitivity Review, Personnel Selection, Cognitive Ability]
categories: [Judgment/Decision-making, Testing/Assessment]
inPress: false
date: '2013-03-07'
lastmod: 2021-05-13T23:46:59-04:00
featured: false
draft: false

# Custom links (uncomment lines below)
links:
- name: Paper
  url: uploads/pubs/Grand et al (2013) -- problematic content detection in sensitivity reviews.pdf
  icon: file-pdf
  icon_pack: far

url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-05-14T03:46:58.979343Z'
publication_types:
- '2'
abstract: In organizational and educational practices, sensitivity reviews are commonly
  advocated techniques for reducing test bias and enhancing fairness. In the present
  paper, results from two studies are reported which investigate how effective individuals
  are at detecting problematic test content and the influence such content has on
  important testing outcomes. In Study 1, signal detection analyses are used to examine
  the role of individual differences in the identification of insensitive test items,
  while Study 2 investigates the extent to which insensitivity differentially influences
  item performance and reactions. Results revealed small but significant differences
  in the overall accuracy and response tendencies of student test reviewers on the
  basis of demographics and key individual differences variables. Contrary to predictions
  however, problematic items did not exhibit differential item functioning across
  sex nor did their presence engender negative test taker reactions. Implications
  and suggestions for future research and sensitivity review practices are discussed.
publication: '*Organizational Behavior and Human Decision Processes, 121*, 158-173'
doi: https://doi.org/10.1016/j.obhdp.2013.01.009
---
